import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import plotly.express as px
import plotly.graph_objects as go
import gc
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression

st.set_page_config(page_title="Fraud Detection Dashboard", layout="wide")
st.title("üîí Fraud Detection Dashboard")

# --- Tabs ---
tab1, tab2, tab3 = st.tabs(["üìÅ D·ªØ li·ªáu & Ph√¢n t√≠ch", "üìà ƒê√°nh gi√° m√¥ h√¨nh", "ü§ñ D·ª± ƒëo√°n"])

# --- Shared ---
fraud_col = None

# ------------------- TAB 1: D·ªÆ LI·ªÜU ------------------- #
with tab1:
    st.subheader("üìä Ph√¢n b·ªë th·ªùi gian giao d·ªãch (`step`) ")

    @st.cache_data
    def load_data():
        return pd.read_csv(r"D:\FPT_Material\Financial-Fraud-Dashboard\data\PS_20174392719_1491204439457_log.csv")

    df = load_data()
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh ·∫£nh h∆∞·ªüng df g·ªëc
    prep_df = df.copy()

    # T·∫°o ƒë·∫∑c tr∆∞ng: Gi·ªù trong ng√†y (0‚Äì23)
    prep_df['hour_of_day'] = prep_df['step'] % 24

    # Ng∆∞·ª°ng step ƒë∆∞·ª£c xem l√† nguy hi·ªÉm
    RISK_THRESHOLD_STEP = 400
    prep_df['is_high_risk_step_period'] = (prep_df['step'] > RISK_THRESHOLD_STEP).astype(int)

    # T·∫°o label d·ªÖ hi·ªÉu cho bi·ªÉu ƒë·ªì
    prep_df["risk_period_label"] = prep_df["is_high_risk_step_period"].map({
        0: f"Normal Period (step ‚â§ {RISK_THRESHOLD_STEP})",
        1: f"High-Risk Period (step > {RISK_THRESHOLD_STEP})"
    })

    # _____________________________________________
    
    fig = px.histogram(
        df,
        x='step',
        nbins=100,
        title="Distribution of Time Step (step)",
        color_discrete_sequence=['dodgerblue']
    )
    fig.update_layout(
        xaxis_title="Step (Time Step)",
        yaxis_title="Number of Transactions",
        bargap=0.01,
        template="plotly_white"
    )

    st.plotly_chart(fig, use_container_width=True)
    # _____________________________________________
    
        # T√≠nh to√°n t·ªïng v√† gian l·∫≠n theo step
    step_analysis = df.groupby("step").agg(
        total_transactions=('isFraud', 'count'),
        fraud_transactions=('isFraud', 'sum')
    ).reset_index()

    step_analysis['fraud_percentage'] = (
        step_analysis['fraud_transactions'] / step_analysis['total_transactions'] * 100
    )

    # V·∫Ω bi·ªÉu ƒë·ªì dual-axis
    fig2 = go.Figure()

    # Bar: T·ªïng s·ªë giao d·ªãch
    fig2.add_trace(go.Bar(
        x=step_analysis["step"],
        y=step_analysis["total_transactions"],
        name="Total Transactions",
        marker_color="lightblue",
        yaxis="y1"
    ))

    # Line: % gian l·∫≠n
    fig2.add_trace(go.Scatter(
        x=step_analysis["step"],
        y=step_analysis["fraud_percentage"],
        name="Fraud Percentage (%)",
        mode="lines+markers",
        marker=dict(color="red"),
        yaxis="y2"
    ))

    # C·∫•u h√¨nh layout 2 tr·ª•c
    fig2.update_layout(
        title="üìà Total Transactions and Fraud Percentage by Step",
        xaxis=dict(title="Step (Time Step)"),
        yaxis=dict(title="Total Transactions", side="left", showgrid=False),
        yaxis2=dict(
            title="Fraud Percentage (%)",
            overlaying="y",
            side="right",
            showgrid=False
        ),
        legend=dict(x=0.01, y=0.99),
        bargap=0.05,
        template="plotly_white"
    )

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
    st.subheader("üìà Giao d·ªãch v√† t·ª∑ l·ªá gian l·∫≠n theo th·ªùi gian (`step`)")
    st.plotly_chart(fig2, use_container_width=True)
    # _____________________________________________
        # L·ªçc ch·ªâ c√°c giao d·ªãch gian l·∫≠n
    fraud_df = df[df['isFraud'] == 1]

    # Plotly histogram ch·ªâ cho isFraud = 1
    fig3 = px.histogram(
        fraud_df,
        x='step',
        nbins=100,
        title="Distribution of Time Step (step) for Fraudulent Transactions",
        color_discrete_sequence=['orangered']
    )

    fig3.update_layout(
        xaxis_title="Step (Time Step)",
        yaxis_title="Number of Fraudulent Transactions",
        bargap=0.01,
        template="plotly_white"
    )

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    st.subheader("üîç Ph√¢n b·ªë th·ªùi gian giao d·ªãch gian l·∫≠n (`isFraud = 1`)")
    st.plotly_chart(fig3, use_container_width=True)
    # _____________________________________________
    

    # Bi·ªÉu ƒë·ªì c·ªôt nh√≥m: s·ªë l∆∞·ª£ng giao d·ªãch theo gi·ªù, ph√¢n chia theo isFraud
    fig4 = px.histogram(
        prep_df,
        x="hour_of_day",
        color="isFraud",
        barmode="group",
        color_discrete_map={0: '#00B7EB', 1: '#FF1493'},
        category_orders={"hour_of_day": list(range(24))},
        title="Fraud vs. Normal Transactions by Hour of the Day"
    )

    fig4.update_layout(
        xaxis_title="Hour of the Day (0‚Äì23)",
        yaxis_title="Number of Transactions",
        legend_title="Fraud Status",
        legend=dict(x=0.8),
        template="plotly_white"
    )

    fig4.update_traces(marker_line_width=1)
    st.subheader("üïí Ph√¢n b·ªë gian l·∫≠n theo gi·ªù trong ng√†y")
    st.plotly_chart(fig4, use_container_width=True)

    # _____________________________________________
    # Bi·ªÉu ƒë·ªì c·ªôt nh√≥m: gian l·∫≠n theo th·ªùi k·ª≥ nguy hi·ªÉm
    # T·ªïng h·ª£p tr∆∞·ªõc: ƒë·∫øm s·ªë giao d·ªãch theo lo·∫°i th·ªùi gian & gian l·∫≠n
    agg_df = prep_df.groupby(["risk_period_label", "isFraud"]).size().reset_index(name="count")

    # T√°ch d·ªØ li·ªáu th√†nh fraud / non-fraud
    normal_counts = agg_df[agg_df['isFraud'] == 0]
    fraud_counts = agg_df[agg_df['isFraud'] == 1]

    # V·∫Ω bar chart th·ªß c√¥ng
    fig5 = go.Figure()

    fig5.add_trace(go.Bar(
        x=normal_counts["risk_period_label"],
        y=normal_counts["count"],
        name="Normal",
        marker_color="#00B7EB"
    ))

    fig5.add_trace(go.Bar(
        x=fraud_counts["risk_period_label"],
        y=fraud_counts["count"],
        name="Fraud",
        marker_color="#FF1493"
    ))

    fig5.update_layout(
        barmode='group',
        title="Fraud vs. Normal Transactions by High-Risk Period",
        xaxis_title="Time Period",
        yaxis_title="Number of Transactions",
        template="plotly_white"
    )

    st.subheader("‚ö†Ô∏è Ph√¢n b·ªë gian l·∫≠n theo v√πng th·ªùi gian nguy hi·ªÉm (`step > 400`)")
    st.plotly_chart(fig5, use_container_width=True)

# --- CLEAN UP: Gi·∫£i ph√≥ng b·ªô nh·ªõ sau tab1 ---
# X√≥a c√°c bi·∫øn kh√¥ng c√≤n s·ª≠ d·ª•ng
del df, prep_df, fraud_df, step_analysis, agg_df

# X√≥a t·∫•t c·∫£ c√°c figure plotly
del fig, fig2, fig3, fig4, fig5

# N·∫øu d√πng cache th√¨ x√≥a cache ƒë·ªÉ gi·∫£i ph√≥ng RAM
load_data.clear()

# √âp Python thu h·ªìi b·ªô nh·ªõ
gc.collect()
    
# ------------------- TAB 2: ƒê√ÅNH GI√Å M√î H√åNH ------------------- #
with tab2:
    st.subheader("üìä ƒê√°nh gi√° m√¥ h√¨nh tr√™n d·ªØ li·ªáu ki·ªÉm th·ª≠")

    st.sidebar.header("T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán v√† d·ªØ li·ªáu test")
    eval_model_file = st.sidebar.file_uploader("Upload m√¥ h√¨nh (pkl/joblib)", type=["pkl", "joblib"], key="eval_model")
    test_data_file = st.sidebar.file_uploader("Upload file test (CSV, c√≥ c·ªôt isFraud)", type=["csv"], key="test_data")

    if eval_model_file and test_data_file:
        try:
            # Load model v√† test data
            model = joblib.load(eval_model_file)
            test_df = pd.read_csv(test_data_file)

            if 'isFraud' not in test_df.columns:
                st.error("‚ö†Ô∏è File test ph·∫£i ch·ª©a c·ªôt `isFraud`.")
            else:
                # ‚ö†Ô∏è Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt ƒë√£ d√πng trong hu·∫•n luy·ªán
                feature_names = [
                    "step", "amount", "isFlaggedFraud",
                    "errorBalanceOrig", "errorBalanceDest", "emptiedAccountOrig",
                    "hour_of_day", "is_high_risk_step_period",
                    "type_CASH_IN", "type_CASH_OUT", "type_DEBIT", "type_PAYMENT", "type_TRANSFER"
                ] 

                # Ki·ªÉm tra thi·∫øu c·ªôt n√†o kh√¥ng
                missing_cols = [col for col in feature_names if col not in test_df.columns]
                if missing_cols:
                    st.error(f"‚ö†Ô∏è File test thi·∫øu c√°c c·ªôt sau: {', '.join(missing_cols)}")
                else:
                    X_test = test_df[feature_names]
                    y_test = test_df["isFraud"]

                    # D·ª± ƒëo√°n
                    y_pred = model.predict(X_test)

                    # Confusion Matrix
                    st.subheader("üìâ Confusion Matrix")
                    cm = confusion_matrix(y_test, y_pred)
                    fig_cm = px.imshow(
                        cm,
                        text_auto=True,
                        color_continuous_scale='blues',
                        x=["Predicted: 0", "Predicted: 1"],
                        y=["Actual: 0", "Actual: 1"],
                        labels=dict(x="Predicted", y="Actual", color="Count"),
                        title="Confusion Matrix"
                    )
                    st.plotly_chart(fig_cm, use_container_width=True)

                    # Classification Report
                    st.subheader("üìë Classification Report")
                    report_str = classification_report(y_test, y_pred, output_dict=False)
                    st.code(report_str)

                    # Hi·ªÉn th·ªã c√°c ch·ªâ s·ªë t·ªïng h·ª£p
                    st.subheader("üìå C√°c ch·ªâ s·ªë ƒë√°nh gi√°")
                    report_dict = classification_report(y_test, y_pred, output_dict=True)
                    st.metric("Precision (Fraud)", f"{report_dict['1']['precision']:.4f}")
                    st.metric("Recall (Fraud)", f"{report_dict['1']['recall']:.4f}")
                    st.metric("F1-score (Fraud)", f"{report_dict['1']['f1-score']:.4f}")
                    st.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.4f}")

                    # ---------------- Feature Importance ----------------
                    st.subheader("üìå Feature Importance (Logistic Regression Coefficients)")
                    try:
                        classifier = model.named_steps['classifier']
                        feature_names_used = X_test.columns
                        importances = classifier.coef_[0]

                        feature_importance_df = pd.DataFrame({
                            'Feature': feature_names_used,
                            'Importance': importances
                        }).sort_values(by='Importance', ascending=False)

                        fig_imp, ax = plt.subplots(figsize=(10, 8))
                        sns.barplot(
                            x='Importance',
                            y='Feature',
                            data=feature_importance_df,
                            palette='viridis',
                            ax=ax
                        )
                        ax.set_title('Feature Importance (Logistic Regression)', fontsize=14)
                        st.pyplot(fig_imp)
                    except Exception as e:
                        st.error(f"‚ùå Kh√¥ng th·ªÉ hi·ªÉn th·ªã Feature Importance: {e}")

                    # ---------------- SHAP Explanation ----------------
                    st.subheader("üîç Gi·∫£i th√≠ch m√¥ h√¨nh v·ªõi SHAP")
                    try:
                        import shap
                        explainer = shap.LinearExplainer(classifier, X_test, feature_perturbation="interventional")
                        shap_values = explainer.shap_values(X_test)

                        # Giao d·ªãch gian l·∫≠n
                        fraud_idx = y_test[y_test == 1].index[0]
                        st.markdown(f"**üìå Giao d·ªãch gian l·∫≠n - Index: {fraud_idx}**")
                        
                        fig_fraud, ax_fraud = plt.subplots(figsize=(10, 6))
                        shap.plots._waterfall.waterfall_legacy(
                            expected_value=explainer.expected_value,
                            shap_values=shap_values[fraud_idx],
                            features=X_test.loc[fraud_idx],
                            feature_names=X_test.columns.tolist(),
                            max_display=10,
                            show=False
                        )
                        st.pyplot(fig_fraud)

                        # Giao d·ªãch kh√¥ng gian l·∫≠n
                        nonfraud_idx = y_test[y_test == 0].index[0]
                        st.markdown(f"**üìå Giao d·ªãch kh√¥ng gian l·∫≠n - Index: {nonfraud_idx}**")
                        
                        fig_nonfraud, ax_nonfraud = plt.subplots(figsize=(10, 6))
                        shap.plots._waterfall.waterfall_legacy(
                            expected_value=explainer.expected_value,
                            shap_values=shap_values[nonfraud_idx],
                            features=X_test.loc[nonfraud_idx],
                            feature_names=X_test.columns.tolist(),
                            max_display=10,
                            show=False
                        )
                        st.pyplot(fig_nonfraud)

                    except Exception as e:
                        st.error(f"‚ùå Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì SHAP: {e}")
        except Exception as e:
            st.error(f"‚ùå ƒê√£ x·∫£y ra l·ªói khi ƒë√°nh gi√° m√¥ h√¨nh: {e}")
    else:
        st.info("üì§ Vui l√≤ng t·∫£i m√¥ h√¨nh v√† d·ªØ li·ªáu test ƒë·ªÉ ƒë√°nh gi√°.")

# ------------------- TAB 3: D·ª∞ ƒêO√ÅN ------------------- #
with tab3:
    st.sidebar.header("Upload m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán")
    model_file = st.sidebar.file_uploader("Upload m√¥ h√¨nh (pkl/joblib)", type=["pkl", "joblib"])

    if model_file:
        model = joblib.load(model_file)
        st.subheader("üîé D·ª± ƒëo√°n m·ªôt giao d·ªãch")
        st.markdown("*Nh·∫≠p gi√° tr·ªã ƒë·∫∑c tr∆∞ng, c√°ch nhau b·∫±ng d·∫•u ph·∫©y.*")

        feature_names = [
            "step", "amount", "isFlaggedFraud", "errorBalanceOrig", "errorBalanceDest",
            "emptiedAccountOrig", "hour_of_day", "is_high_risk_step_period",
            "type_CASH_IN", "type_CASH_OUT", "type_DEBIT", "type_PAYMENT", "type_TRANSFER"
        ]
        st.caption("**C·ªôt ƒë·∫ßu v√†o:** " + ", ".join(feature_names))
        input_str = st.text_input("Nh·∫≠p giao d·ªãch:")

        if st.button("D·ª± ƒëo√°n"):
            try:
                values = [float(x.strip()) for x in input_str.split(",")]
                pred = model.predict([values])[0]
                st.success(f"üëâ K·∫øt qu·∫£: {'Gian l·∫≠n (Fraud)' if pred == 1 else 'Kh√¥ng gian l·∫≠n'}")
            except:
                st.error("‚ö†Ô∏è D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá. H√£y nh·∫≠p ƒë√∫ng s·ªë l∆∞·ª£ng v√† ƒë·ªãnh d·∫°ng.")

        # Batch prediction
        st.subheader("üì• D·ª± ƒëo√°n h√†ng lo·∫°t")
        batch_file = st.file_uploader("Upload file ƒë·ªÉ d·ª± ƒëo√°n h√†ng lo·∫°t (kh√¥ng c√≥ c·ªôt Prediction)", type=["csv"], key="batch")

        if batch_file:
            batch_df = pd.read_csv(batch_file)
            try:
                preds = model.predict(batch_df)
                batch_df['Prediction'] = preds
                st.success("‚úÖ D·ª± ƒëo√°n ho√†n t·∫•t!")
                st.dataframe(batch_df.head())
                csv = batch_df.to_csv(index=False)
                st.download_button("üì• T·∫£i k·∫øt qu·∫£", csv, file_name="predicted_results.csv")
            except Exception as e:
                st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")
